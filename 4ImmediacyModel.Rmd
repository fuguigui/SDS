---
title: "R Notebook"
author: "Haojun Cai"
date: "17/4/2020"
output: html_notebook
---

# Function to read Google trends and process the data
```{r function}
calGoogleTrends <- function(keyword,countries,time,target_nodes){
  library (gtrendsR)
  
  # Obtain data and save as lang+"_GoogleImpact"
  for (country in countries){
    trends = gtrends(keyword,geo=country,time=time)
    time_trend = trends$interest_over_time
    varname = paste(country,"_GoogleImpact",sep="")
    assign(varname,time_trend)
  }
  
  # 1st: cut data with specified dates and save as lang+"_CutGoogleImpact"
  for (country in countries){
    dname = paste(country,"_GoogleImpact",sep="")
    if(country=="IN") {varname = "Hi_CutGoogleImpact"}
    else if(country=="KR") {varname = "Ko_CutGoogleImpact"}
    else if(country=="JP") {varname = "Ja_CutGoogleImpact"}
    else if(country=="RU") {varname = "Ru_CutGoogleImpact"}
    else if(country=="DE") {varname = "De_CutGoogleImpact"}
    else if(country=="IT") {varname = "It_CutGoogleImpact"}
    
    data = get(dname)
    data = data[c(23:78),] # CHOOSE TIME DURATION IN 02.09 - 04.18
    assign(varname,data)
  }
  
  # 2nd: deal with hits attribute
  tempdata = c()
  for (target in target_nodes){
    dname = paste(target,"_CutGoogleImpact",sep="")
    varname = paste(target,"GgImpact",sep="")
    data = get(dname)
    data = data$hits
    for (i in 1:length(data)){
      if (data[i]=="<1"){
        tempdata[i]=0.5
      } else{
        tempdata[i]=as.numeric(data[i]) 
      }
    }
    assign(varname,tempdata)
  }
  return(list("HiGoogleTrend"=HiGgImpact,"KoGoogleTrend"=KoGgImpact,"RuGoogleTrend"=RuGgImpact,"JaGoogleTrend"=JaGgImpact,"DeGoogleTrend"=DeGgImpact,"ItGoogleTrend"=ItGgImpact))
}
```

# Calculate distance matrix of geolocation
```{r}
calGeoDistMatrix <- function(source_nodes,target_nodes,node_geo){
  geo_dist = c()
  
  for (i in 1:length(target_nodes)){
    target = target_nodes[i]
    target_dist = c()
    lat = node_geo[node_geo$Node==target,]$lat
    long = node_geo[node_geo$Node==target,]$long
    target_loc = c(lat,long)
    
    for (source in source_nodes){
      lat = node_geo[node_geo$Node==source,]$lat
      long = node_geo[node_geo$Node==source,]$long
      source_loc = c(lat,long) 
      target_dist <- append(target_dist,dist(rbind(target_loc,source_loc)))
    }
    
   geo_dist <- append(geo_dist,target_dist)
  }
  
  geo_dist_matrix <- matrix(geo_dist, ncol=length(source_nodes), byrow=TRUE)
  geo_dist <- as.data.frame(geo_dist_matrix, stringsAsFactors=FALSE)
  
  colnames(geo_dist) = source_nodes
  rownames(geo_dist) = target_nodes

  return(geo_dist)
}
```

## Test the relevance btw immediacy and impact
# Alternative 1: Twitter impact
```{r}
# library(Hmisc)
# rcorr(x, type="pearson") # type can be pearson or spearman
calFeatTwitter <- function(test_targets,test_sources,TwitterImpact){
  cor = c()
  pval = c()
  for (target in test_targets){
    target = tolower(target)
    
    for (source in test_sources){
      dname = paste(source,"_weight",sep="")
      source_weight = get(dname)

      sumry = cor.test(source_weight,TwitterImpact[,target])
      pvalue = sumry$p.value
      targetcor= sumry$estimate
      
      cor = append(cor,targetcor)
      pval = append(pval,pvalue)
      # plot(source_weight, TwitterImpact$de, xlab="Features", ylab="Impacts")
    }
  }
  
  cor_matrix <- matrix(cor, ncol=length(test_sources), byrow=TRUE)
  correlation <- as.data.frame(cor_matrix, stringsAsFactors=FALSE)
  colnames(correlation) = test_sources
  rownames(correlation) = test_targets
  
  pval_matrix <- matrix(pval, ncol=length(test_sources), byrow=TRUE)
  pvalue <- as.data.frame(pval_matrix, stringsAsFactors=FALSE)
  colnames(pvalue) = test_sources
  rownames(pvalue) = test_targets
  
  return(list("cor"=correlation,"pval"=pvalue))
  # print(correlation)
}
```

# Alternative 2: Google impact
```{r}
calFeatGoogle <- function(test_targets,test_sources){
  cor = c()
  pval = c()
  
  for (target in test_targets){
    dname = paste(target,"GoogleImpact",sep="")
    impact = get(dname)
    
    for (source in test_sources){
      dname = paste(source,"_weight",sep="")
      source_weight = get(dname)
      
      sumry = cor.test(source_weight,impact[,2])
      pvalue = sumry$p.value
      targetcor= sumry$estimate
      
      cor = append(cor,targetcor)
      pval = append(pval,pvalue)
      
      # plot(source_weight, TwitterImpact$de, xlab="Features", ylab="Impacts")
    }
  }
  
  cor_matrix <- matrix(cor, ncol=length(test_sources), byrow=TRUE)
  correlation <- as.data.frame(cor_matrix, stringsAsFactors=FALSE)
  colnames(correlation) = test_sources
  rownames(correlation) = test_targets
  
  pval_matrix <- matrix(pval, ncol=length(test_sources), byrow=TRUE)
  pvalue <- as.data.frame(pval_matrix, stringsAsFactors=FALSE)
  colnames(pvalue) = test_sources
  rownames(pvalue) = test_targets
  
  return(list("cor"=correlation,"pval"=pvalue))
}
```

## Calculate coorelation between geodistance and above source-target-coorelations
# Alternative 1: Geo distance
```{r}
calcorCorGeodist <- function(test_targets,correlation,geo_dist){
  # Calculate the reciprocal of the distance, so that larger value coresponds to larger impact ideally
  for (i in 1:nrow(geo_dist)){
    for (j in 1:ncol(geo_dist)){
      geo_dist[i,j] = 1/geo_dist[i,j]
    }
  }
  
  # Calculate coorelations
  TargetDistCor = c()
  pval = c()
  
  for (target in test_targets){
    targetcor = correlation[c(target),]
    targetdist = sort(geo_dist[c(target),])
    sortcolnames <- colnames(targetdist)
    targetcor <- targetcor[,sortcolnames] # Sort the coorelation based on descending distance
    targetcor <- t(targetcor)
    targetdist <- t(targetdist)
  
    sumry = cor.test(targetcor,targetdist)
    pvalue = sumry$p.value
    cor= sumry$estimate
    
    TargetDistCor = append(TargetDistCor,cor)
    pval = append(pval,pvalue)
  }
  
  TargetDistCor_matrix <- matrix(TargetDistCor, ncol=length(target_nodes), byrow=TRUE)
  TargetDistCor <- as.data.frame(TargetDistCor_matrix, stringsAsFactors=FALSE)
  colnames(TargetDistCor) = target_nodes
  
  pval_matrix <- matrix(pval, ncol=length(target_nodes), byrow=TRUE)
  pvalue <- as.data.frame(pval_matrix, stringsAsFactors=FALSE)
  colnames(pvalue) = target_nodes
  
  return(list("cor"=TargetDistCor,"pval"=pvalue))
  
}  
```

## Alternative 2: Shorteset path
```{r}
calcorCorPath <- function(test_targets,correlation,short_paths){
  # Calculate the reciprocal of the distance
  pathDist <- short_paths[,c(source_nodes)]
  rownames(pathDist) = short_paths[,c("X")]
  pathDist = pathDist[c(target_nodes),]
  
  for (i in 1:nrow(pathDist)){
    for (j in 1:ncol(pathDist)){
      if(pathDist[i,j]!=0) pathDist[i,j] = 1/pathDist[i,j]
    }
  }
  
  # Calculate coorelations
  geo_dist = pathDist
  TargetDistCor = c()
  pval = c()
  
  for (target in test_targets){
    targetcor = correlation[c(target),]
    targetdist = sort(geo_dist[c(target),])
    sortcolnames <- colnames(targetdist)
    targetcor <- targetcor[,sortcolnames] # Sort the coorelation based on descending distance
    targetcor <- t(targetcor)
    targetdist <- t(targetdist)

    sumry = cor.test(targetcor,targetdist)
    pvalue = sumry$p.value
    cor= sumry$estimate
    
    TargetDistCor = append(TargetDistCor,cor)
    pval = append(pval,pvalue)
  }

  TargetDistCor_matrix <- matrix(TargetDistCor, ncol=length(target_nodes), byrow=TRUE)
  TargetDistCor <- as.data.frame(TargetDistCor_matrix, stringsAsFactors=FALSE)
  colnames(TargetDistCor) = target_nodes
  
  pval_matrix <- matrix(pval, ncol=length(target_nodes), byrow=TRUE)
  pvalue <- as.data.frame(pval_matrix, stringsAsFactors=FALSE)
  colnames(pvalue) = target_nodes
  
  return(list("cor"=TargetDistCor,"pval"=pvalue))
}

```

# Set the working directory
```{r setup, include=FALSE}
# knitr::opts_knit$set(root.dir = "E:/5_Social Data Science/old_keyword")
setwd("E:/5_Social Data Science/old_keyword")
```

## Deal with data within 02.09 - 04.18 (features, impacts)
## Parameters to test: source weights, twitter impact, distance matrix
# Read Google impacts, immediacy data (geolocation and shortest path), Twitter impacts, source features
```{r}
source_nodes = c("Eu1","Eu2","Eu3","Eu4","Eu5","Eu6","Eu7","Au","As1","As2","As3","As4","As5","Am1","Am2","Am3","Af1","Af2")
target_nodes = c("Hi","Ko","Ru","Ja","De","It")

## Read Google trends impact
# Alternative 1: read the data from pre-saved file
HiGoogleTrend <- read.csv("./Data/Google/india.csv")
KoGoogleTrend <- read.csv("./Data/Google/southkorea.csv")
RuGoogleTrend <- read.csv("./Data/Google/russia.csv")
JaGoogleTrend <- read.csv("./Data/Google/japan.csv")
DeGoogleTrend <- read.csv("./Data/Google/germany.csv")
ItGoogleTrend <- read.csv("./Data/Google/italy.csv")
GoogleTrends_chosen_date = c(19:88) # CHOOSE TIME DURATION IN 02.09 - 04.18
HiGoogleImpact = HiGoogleTrend[GoogleTrends_chosen_date,]
KoGoogleImpact = KoGoogleTrend[GoogleTrends_chosen_date,]
RuGoogleImpact = RuGoogleTrend[GoogleTrends_chosen_date,]
JaGoogleImpact = JaGoogleTrend[GoogleTrends_chosen_date,]
DeGoogleImpact = DeGoogleTrend[GoogleTrends_chosen_date,]
ItGoogleImpact = ItGoogleTrend[GoogleTrends_chosen_date,]

# Alternative 2: obtain real-time Google trends data 
# keyword = "coronavirus"
# countries = c("IN","KR","RU","JP","DE","IT")
# time = "today 3-m"
# GoogleImpatcs <- calGoogleTrends(keyword,countries,time,target_nodes)
# HiGoogleImpact <- GoogleImpatcs$HiGoogleTrend
# KoGoogleImpact <- GoogleImpatcs$KoGoogleTrend
# RuGoogleImpact <- GoogleImpatcs$RuGoogleTrend
# JaGoogleImpact <- GoogleImpatcs$JaGoogleTrend
# DeGoogleImpact <- GoogleImpatcs$DeGoogleTrend
# ItGoogleImpact <- GoogleImpatcs$ItGoogleTrend

# Read immediacy data (geodistance and shortest path) and calculate geodistance matrix
short_paths <- read.csv("./Data/Nodes/shortest_path.csv")
node_geo <- read.csv("./Data/Nodes/node_geo.csv")
member <- read.csv("./Data/Nodes/node_member.csv")
geo_dist <- calGeoDistMatrix(source_nodes,target_nodes,node_geo)

# Read Twitter impact
TwitterImpact <- read.csv("./Data/0421TweetsStatistics.csv")

```

# Calculate coorelation between source weights and impacts
## TEST 1 STARTS
TEST 1: Confirmed, *Twitter & Google impacts*
```{r}
feat_chosen_dates = c(19:88) # CHOOSE TIME DURATION IN 02.09 - 04.18

# Change test_srouce and test_targets to test different variables
test_targets = target_nodes
test_sources = source_nodes

# Read source features
for (source in test_sources){
  varname = paste(source,"_source_feat",sep="")
  source_feat = read.csv(paste("./Data/Nodes/features/",source,".csv",sep=""))
  source_feat = source_feat[feat_chosen_dates,] 
  assign(varname,source_feat)
}

# Calculate weighted source features
for (source in test_sources){
  dname = paste(source,"_source_feat",sep="")
  varname = paste(source,"_weight",sep="")
  source_feat = get(dname)
  # source_weight = source_feat$confirm*0.5+source_feat$death*0.3+source_feat$recover*0.2
  source_weight = source_feat$confirm
  assign(varname,source_weight)
  # plot(source_weight)
}

sumryFeatTwitter <- calFeatTwitter(test_targets,test_sources,TwitterImpact)
corFeatTwitter <- sumryFeatTwitter$cor
pvalFeatTwitter <- sumryFeatTwitter$pval
print(corFeatTwitter)
print(pvalFeatTwitter)

sumryFeatGoogle <- calFeatGoogle(test_targets,test_sources)
corFeatGoogle <- sumryFeatGoogle$cor
pvalFeatGoogle <- sumryFeatGoogle$pval
print(corFeatGoogle)
print(pvalFeatGoogle)
```
Conclusion 1.1.1 (confirmed, Twitter impact): With accumulated confirmed cases and Twitter impacts, *Hi and Ru* show positive relationships between the above two indexes, which accords to the null assumptions.
Conclusion 1.1.2 (confirmed, Google impact): With accumulated confirmed cases and Google impacts, *Hi, Ru, Ko, Ja* show positive relationships between the above two indexes, which accords to the null assumptions. *Also, Hi and Ru shows more positive relationships compared to the twitter impacts.*

TEST 1 continuted: Confirmed, Twitter impacts, *Geolocation distance & Shortest path*
```{r}
sumryCorGeodist <- calcorCorGeodist(test_targets,corFeatTwitter,geo_dist)
corCorGeodist <- sumryCorGeodist$cor
pvalCorGeodist <- sumryCorGeodist$pval
print(corCorGeodist)
print(pvalCorGeodist)

sumryCorPath <- calcorCorPath(test_targets,corFeatTwitter,short_paths)
corCorPath <- sumryCorPath$cor
pvalCorPath <- sumryCorPath$pval
print(corCorPath)
print(pvalCorPath)

```
Conclusion 1.2.1 (confirmed, Twitter impact, geodistance): With smaller distance (larger value after inversion), the devotion of the coorelation between source features and target impacts should be larger. Thus, there exists a postive coorelation between the inversed distance and coorelation. Here, *Ko and Ja* shows the trends, but with very weak positive relationships.
Conclusion 1.2.2 (confirmed, Twitter impact, shortest path): Here, *Ko, Ja, Hi* shows the trends, while they are smaller compared to the geodistance. 
Conclusion 2: Combined with the results from last section, that only *Hi and Ru* show positive relationships between source features and Twitter impact, we can only conclude that for geolocation distance, *no one* shows weak postive relationships with repsect to the distances and impacts. For shortest path distance, *Hi* shows weak relationships.

TEST 1 continued: Confirmed, *Google impacts*, Geolocation distance & Shortest path
```{r}
sumryCorGeodist <- calcorCorGeodist(test_targets,corFeatGoogle,geo_dist)
corCorGeodist <- sumryCorGeodist$cor
pvalCorGeodist <- sumryCorGeodist$pval
print(corCorGeodist)
print(pvalCorGeodist)

sumryCorPath <- calcorCorPath(test_targets,corFeatGoogle,short_paths)
corCorPath <- sumryCorPath$cor
pvalCorPath <- sumryCorPath$pval
print(corCorPath)
print(pvalCorPath)
```
Conclusion 1.3.1 (confirmed, Google impact, geodistance): Here, *Ko and Ja* shows the trend.
Conclusion 1.3.2 (confirmed, Google impact, shortest path): Here, *Ko and Ja* shows the trends.
Conclusion 1.3: Combined results from coorelation between source features and target impacts, for geolocation distance, *Ko and Ja* shows the relationships. For shortest path, *Ko and Ja* show the trends. And geolocation distance coorelation show stronger positive effects than shortest-path.

## TEST 2 STARTS
TEST 2: *Confirmed_daily*, Twitter & Google impacts
```{r}
feat_chosen_dates = c(19:88) # CHOOSE TIME DURATION IN 02.09 - 04.18

# Change test_srouce and test_targets to test different variables
test_targets = target_nodes
test_sources = source_nodes

# Read source features
for (source in test_sources){
  varname = paste(source,"_source_feat",sep="")
  source_feat = read.csv(paste("./Data/Nodes/features/",source,".csv",sep=""))
  source_feat = source_feat[feat_chosen_dates,] 
  assign(varname,source_feat)
}

# Calculate weighted source features
for (source in test_sources){
  dname = paste(source,"_source_feat",sep="")
  varname = paste(source,"_weight",sep="")
  source_feat = get(dname)
  # Alternative 1: confirm_accumulated
  # source_weight = source_feat$confirm 
  
  # Alternative 2: confirm_daily
  source_weight = source_feat$confirm_daily
  assign(varname,source_weight)
  # plot(source_weight)
}

sumryFeatTwitter <- calFeatTwitter(test_targets,test_sources,TwitterImpact)
corFeatTwitter <- sumryFeatTwitter$cor
pvalFeatTwitter <- sumryFeatTwitter$pval
print(corFeatTwitter)
print(pvalFeatTwitter)

sumryFeatGoogle <- calFeatGoogle(test_targets,test_sources)
corFeatGoogle <- sumryFeatGoogle$cor
pvalFeatGoogle <- sumryFeatGoogle$pval
print(corFeatGoogle)
print(pvalFeatGoogle)
```
Conclusion 2.1.1 (confirmed_daily, Twitter impact): With daily confirmed cases and Twitter impacts, *Hi, Ru, De* show positive relationships between the above two indexes, which accords to the null assumptions. *They are much larger then the confimed_accumulated VS Twitter impact*
Conclusion 2.1.2 (confirmed_daily, Google impact): With accumulated confirmed cases and Google impacts, *Hi, Ru, Ja, Ko* show positive relationships between the above two indexes, which accords to the null assumptions. 

TEST 1 continuted: Confirmed_daily, Twitter impacts, *Geolocation distance & Shortest path*
```{r}
sumryCorGeodist <- calcorCorGeodist(test_targets,corFeatTwitter,geo_dist)
corCorGeodist <- sumryCorGeodist$cor
pvalCorGeodist <- sumryCorGeodist$pval
print(corCorGeodist)
print(pvalCorGeodist)

sumryCorPath <- calcorCorPath(test_targets,corFeatTwitter,short_paths)
corCorPath <- sumryCorPath$cor
pvalCorPath <- sumryCorPath$pval
print(corCorPath)
print(pvalCorPath)
```
Conclusion 2.2.1 (confirmed_daily, Twitter impact, geodistance): Here, *Ko, Ja, De, It* shows the trends.
Conclusion 2.2.2 (confirmed_daily, Twitter impact, shortest path): Here, *Ko, Ja, De, It* shows the trends, *Ko and It are smaller than the geolocation distance while Ja and De are higher*
Conclusion 2.2 Combined with the results from last section, for geolocation distance, *De* shows weak postive relationships with repsect to the distances and impacts. For shortest path distance, *De* shows weak relationships.

TEST 1 continued: Confirmed_daily, *Google impacts*, Geolocation distance & Shortest path
```{r}
sumryCorGeodist <- calcorCorGeodist(test_targets,corFeatGoogle,geo_dist)
corCorGeodist <- sumryCorGeodist$cor
pvalCorGeodist <- sumryCorGeodist$pval
print(corCorGeodist)
print(pvalCorGeodist)

sumryCorPath <- calcorCorPath(test_targets,corFeatGoogle,short_paths)
corCorPath <- sumryCorPath$cor
pvalCorPath <- sumryCorPath$pval
print(corCorPath)
print(pvalCorPath)
```
Conclusion 2.3.1 (confirmed_daily, Google impact, geodistance): Here, *De, It* shows the trend, but weak ones.
Conclusion 2.3.2 (confirmed_daily, Google impact, shortest path): Here, *De, It* shows the trends.
Conclusion 2.3 Combined results from coorelation between source features and target impacts, *no one* shows the trends.


